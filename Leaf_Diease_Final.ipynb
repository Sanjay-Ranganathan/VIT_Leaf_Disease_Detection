{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4oP-FUScepL",
        "outputId": "c3681ed3-98b6-48ee-fe88-fe9190e6914e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = '/content/drive/MyDrive/Dataset'\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZtguSTDcpjY",
        "outputId": "22081aa9-a4a6-4273-ba5f-b543e13e3c0d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['brinjal _cercospora leaf spot', 'naval_healthy', 'Lotus Rotting tubers', 'Brinjal Tobacco mosaic virus', 'Lotus nutrient deficiency  and rotting tubers', 'naval_anthracnose', 'naval_leaf_galls']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LExqJ72WLmJr",
        "outputId": "c8e52b75-eade-444e-b0ea-ff406b850127"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv('/content/drive/MyDrive/SECRET.env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNCwUmAYLto2",
        "outputId": "151acd0e-5a08-4bcf-d00c-46beebfc5dfc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch, shutil, numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, root, transformations=None):\n",
        "    self.root = root\n",
        "    self.transformations = transformations\n",
        "    self.im_paths = sorted(glob(f\"{root}/*/*\"))\n",
        "    self.class_names, self.class_counts, count = {}, {}, 0\n",
        "    for idx, im_path in enumerate(self.im_paths):\n",
        "      classname = self.getClassName(im_path)\n",
        "      if classname not in self.class_names:\n",
        "        self.class_names[classname] = count\n",
        "        self.class_counts[classname] = 1\n",
        "        count += 1\n",
        "      else:\n",
        "        self.class_counts[classname] += 1\n",
        "\n",
        "  def getClassName(self, path):\n",
        "      return os.path.dirname(path).split('/')[-1]\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.im_paths)\n",
        "  def __getitem__(self, idx):\n",
        "     im_path = self.im_paths[idx]\n",
        "     im = Image.open(im_path).convert(\"RGB\")\n",
        "     gt = self.class_names[self.getClassName(im_path)]\n",
        "\n",
        "     if self.transformations:\n",
        "      im = self.transformations(im)\n",
        "\n",
        "     return im, gt\n",
        "\n",
        "\n",
        "def get_dls(root, transformations, bs, split=[0.7, 0.15, 0.15], ns=2):\n",
        "  ds = CustomDataset(root=root, transformations=transformations)\n",
        "\n",
        "  tot_len = len(ds)\n",
        "  tr_len = int(tot_len*split[0])\n",
        "  vl_len = int(tot_len*split[1])\n",
        "  ts_len = tot_len - tr_len - vl_len\n",
        "\n",
        "  tr_ds, vl_ds, ts_ds = random_split(dataset=ds, lengths=[tr_len, vl_len, ts_len])\n",
        "  tr_dl = DataLoader(tr_ds, batch_size=bs, shuffle=True, num_workers=ns)\n",
        "  vl_dl = DataLoader(vl_ds, batch_size=bs, shuffle=False, num_workers=ns)\n",
        "  ts_dl = DataLoader(ts_ds, batch_size=bs, shuffle=False, num_workers=ns)\n",
        "\n",
        "  return tr_dl, vl_dl, ts_dl, ds.class_counts, ds.class_names, ds.im_paths\n",
        "\n",
        "root = path\n",
        "mean, std, im_size = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 224\n",
        "tfs = T.Compose([\n",
        "    T.Resize((im_size, im_size)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    # T.RandomVerticalFlip(),\n",
        "    # T.RandomRotation(20),\n",
        "    # T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    # T.RandomResizedCrop(im_size, scale=(0.8, 1.0)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "tr_dl, vl_dl, ts_dl, class_counts, classes, im_paths = get_dls(root, tfs, 16)\n",
        "\n",
        "print(len(tr_dl), len(vl_dl), len(ts_dl))\n",
        "print(class_counts)\n",
        "print(len(im_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwIMCsVWTt-X",
        "outputId": "4764d7e9-91b3-423d-d0fd-0248b5cf99a3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 2 2\n",
            "{'Brinjal Tobacco mosaic virus': 9, 'Lotus Rotting tubers': 46, 'Lotus nutrient deficiency  and rotting tubers': 15, 'brinjal _cercospora leaf spot': 9, 'naval_anthracnose': 29, 'naval_healthy': 8, 'naval_leaf_galls': 31}\n",
            "147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm torchmetrics torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6CjhFgdZ7zQ",
        "outputId": "d8571ba7-3189-4133-d2fe-12ed1fd1cf62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.28.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(os.getenv('HUG_LOGIN_ID'))"
      ],
      "metadata": {
        "id": "creyn3kvoXEe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm, torchmetrics\n",
        "from tqdm import tqdm\n",
        "\n",
        "m = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=len(classes))\n",
        "\n",
        "def train_setup(m): return m.to(\"cuda\").eval(), 15, \"cuda\", torch.nn.CrossEntropyLoss(), torch.optim.Adam(params = m.parameters(), lr = 1e-5)\n",
        "def to_device(batch, device): return batch[0].to(device), batch[1].to(device)\n",
        "def get_metrics(model, ims, gts, loss_fn, epoch_loss, epoch_acc, epoch_f1): preds = model(ims); loss = loss_fn(preds, gts); return loss, epoch_loss + (loss.item()), epoch_acc + (torch.argmax(preds, dim = 1) == gts).sum().item(), epoch_f1 + f1_score(preds, gts)\n",
        "\n",
        "m, epochs, device, loss_fn, optimizer = train_setup(m)\n",
        "\n",
        "f1_score = torchmetrics.F1Score(task = \"multiclass\", num_classes = len(classes)).to(device)\n",
        "save_prefix, save_dir = \"child_wound\", \"saved_models\"\n",
        "print(\"Start training...\")\n",
        "best_acc, best_loss, threshold, not_improved, patience = 0, float(\"inf\"), 0.01, 0, 5\n",
        "tr_losses, val_losses, tr_accs, val_accs, tr_f1s, val_f1s = [], [], [], [], [], []\n",
        "\n",
        "best_loss = float(torch.inf)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    epoch_loss, epoch_acc, epoch_f1 = 0, 0, 0\n",
        "    for idx, batch in tqdm(enumerate(tr_dl)):\n",
        "\n",
        "        ims, gts = to_device(batch, device)\n",
        "\n",
        "        loss, epoch_loss, epoch_acc, epoch_f1 = get_metrics(m, ims, gts, loss_fn, epoch_loss, epoch_acc, epoch_f1)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "\n",
        "    tr_loss_to_track = epoch_loss / len(tr_dl)\n",
        "    tr_acc_to_track  = epoch_acc  / len(tr_dl.dataset)\n",
        "    tr_f1_to_track   = epoch_f1   / len(tr_dl)\n",
        "    tr_losses.append(tr_loss_to_track); tr_accs.append(tr_acc_to_track); tr_f1s.append(tr_f1_to_track)\n",
        "\n",
        "    print(f\"{epoch + 1}-epoch train process is completed!\")\n",
        "    print(f\"{epoch + 1}-epoch train loss          -> {tr_loss_to_track:.3f}\")\n",
        "    print(f\"{epoch + 1}-epoch train accuracy      -> {tr_acc_to_track:.3f}\")\n",
        "    print(f\"{epoch + 1}-epoch train f1-score      -> {tr_f1_to_track:.3f}\")\n",
        "\n",
        "    m.eval()\n",
        "    with torch.no_grad():\n",
        "        val_epoch_loss, val_epoch_acc, val_epoch_f1 = 0, 0, 0\n",
        "        for idx, batch in enumerate(vl_dl):\n",
        "            ims, gts = to_device(batch, device)\n",
        "            loss, val_epoch_loss, val_epoch_acc, val_epoch_f1 = get_metrics(m, ims, gts, loss_fn, val_epoch_loss, val_epoch_acc, val_epoch_f1)\n",
        "\n",
        "        val_loss_to_track = val_epoch_loss / len(vl_dl)\n",
        "        val_acc_to_track  = val_epoch_acc  / len(vl_dl.dataset)\n",
        "        val_f1_to_track   = val_epoch_f1   / len(vl_dl)\n",
        "        val_losses.append(val_loss_to_track); val_accs.append(val_acc_to_track); val_f1s.append(val_f1_to_track)\n",
        "\n",
        "        print(f\"{epoch + 1}-epoch validation process is completed!\")\n",
        "        print(f\"{epoch + 1}-epoch validation loss     -> {val_loss_to_track:.3f}\")\n",
        "        print(f\"{epoch + 1}-epoch validation accuracy -> {val_acc_to_track:.3f}\")\n",
        "        print(f\"{epoch + 1}-epoch validation f1-score -> {val_f1_to_track:.3f}\")\n",
        "\n",
        "        if val_loss_to_track < (best_loss + threshold):\n",
        "            os.makedirs(save_dir, exist_ok = True)\n",
        "            best_loss = val_loss_to_track\n",
        "            torch.save(m.state_dict(), f\"{save_dir}/{save_prefix}_best_model.pth\")\n",
        "\n",
        "        else:\n",
        "            not_improved += 1\n",
        "            print(f\"Loss value did not decrease for {not_improved} epochs\")\n",
        "            if not_improved == patience:\n",
        "                print(f\"Stop training since loss value did not decrease for {patience} epochs.\")\n",
        "                break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XqKKPRraKNr",
        "outputId": "c5839ae6-38a8-439e-9c6d-ff0846f09d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-epoch train process is completed!\n",
            "1-epoch train loss          -> 1.726\n",
            "1-epoch train accuracy      -> 0.402\n",
            "1-epoch train f1-score      -> 0.396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-epoch validation process is completed!\n",
            "1-epoch validation loss     -> 1.543\n",
            "1-epoch validation accuracy -> 0.455\n",
            "1-epoch validation f1-score -> 0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-epoch train process is completed!\n",
            "2-epoch train loss          -> 0.748\n",
            "2-epoch train accuracy      -> 0.676\n",
            "2-epoch train f1-score      -> 0.690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-epoch validation process is completed!\n",
            "2-epoch validation loss     -> 0.943\n",
            "2-epoch validation accuracy -> 0.636\n",
            "2-epoch validation f1-score -> 0.594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3-epoch train process is completed!\n",
            "3-epoch train loss          -> 0.331\n",
            "3-epoch train accuracy      -> 0.922\n",
            "3-epoch train f1-score      -> 0.929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3-epoch validation process is completed!\n",
            "3-epoch validation loss     -> 0.695\n",
            "3-epoch validation accuracy -> 0.773\n",
            "3-epoch validation f1-score -> 0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4-epoch train process is completed!\n",
            "4-epoch train loss          -> 0.169\n",
            "4-epoch train accuracy      -> 0.971\n",
            "4-epoch train f1-score      -> 0.973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4-epoch validation process is completed!\n",
            "4-epoch validation loss     -> 0.619\n",
            "4-epoch validation accuracy -> 0.773\n",
            "4-epoch validation f1-score -> 0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-epoch train process is completed!\n",
            "5-epoch train loss          -> 0.064\n",
            "5-epoch train accuracy      -> 0.990\n",
            "5-epoch train f1-score      -> 0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-epoch validation process is completed!\n",
            "5-epoch validation loss     -> 0.579\n",
            "5-epoch validation accuracy -> 0.773\n",
            "5-epoch validation f1-score -> 0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6-epoch train process is completed!\n",
            "6-epoch train loss          -> 0.035\n",
            "6-epoch train accuracy      -> 0.990\n",
            "6-epoch train f1-score      -> 0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6-epoch validation process is completed!\n",
            "6-epoch validation loss     -> 0.623\n",
            "6-epoch validation accuracy -> 0.818\n",
            "6-epoch validation f1-score -> 0.823\n",
            "Loss value did not decrease for 1 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:03,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7-epoch train process is completed!\n",
            "7-epoch train loss          -> 0.032\n",
            "7-epoch train accuracy      -> 0.990\n",
            "7-epoch train f1-score      -> 0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7-epoch validation process is completed!\n",
            "7-epoch validation loss     -> 0.801\n",
            "7-epoch validation accuracy -> 0.818\n",
            "7-epoch validation f1-score -> 0.823\n",
            "Loss value did not decrease for 2 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8-epoch train process is completed!\n",
            "8-epoch train loss          -> 0.031\n",
            "8-epoch train accuracy      -> 0.990\n",
            "8-epoch train f1-score      -> 0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8-epoch validation process is completed!\n",
            "8-epoch validation loss     -> 0.612\n",
            "8-epoch validation accuracy -> 0.818\n",
            "8-epoch validation f1-score -> 0.823\n",
            "Loss value did not decrease for 3 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9-epoch train process is completed!\n",
            "9-epoch train loss          -> 0.014\n",
            "9-epoch train accuracy      -> 1.000\n",
            "9-epoch train f1-score      -> 1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9-epoch validation process is completed!\n",
            "9-epoch validation loss     -> 0.587\n",
            "9-epoch validation accuracy -> 0.773\n",
            "9-epoch validation f1-score -> 0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:03,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-epoch train process is completed!\n",
            "10-epoch train loss          -> 0.039\n",
            "10-epoch train accuracy      -> 0.980\n",
            "10-epoch train f1-score      -> 0.982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-epoch validation process is completed!\n",
            "10-epoch validation loss     -> 0.511\n",
            "10-epoch validation accuracy -> 0.818\n",
            "10-epoch validation f1-score -> 0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:03,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11-epoch train process is completed!\n",
            "11-epoch train loss          -> 0.022\n",
            "11-epoch train accuracy      -> 0.990\n",
            "11-epoch train f1-score      -> 0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11-epoch validation process is completed!\n",
            "11-epoch validation loss     -> 0.492\n",
            "11-epoch validation accuracy -> 0.818\n",
            "11-epoch validation f1-score -> 0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12-epoch train process is completed!\n",
            "12-epoch train loss          -> 0.017\n",
            "12-epoch train accuracy      -> 0.980\n",
            "12-epoch train f1-score      -> 0.982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12-epoch validation process is completed!\n",
            "12-epoch validation loss     -> 0.555\n",
            "12-epoch validation accuracy -> 0.818\n",
            "12-epoch validation f1-score -> 0.823\n",
            "Loss value did not decrease for 4 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:04,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13-epoch train process is completed!\n",
            "13-epoch train loss          -> 0.026\n",
            "13-epoch train accuracy      -> 0.990\n",
            "13-epoch train f1-score      -> 0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13-epoch validation process is completed!\n",
            "13-epoch validation loss     -> 0.602\n",
            "13-epoch validation accuracy -> 0.818\n",
            "13-epoch validation f1-score -> 0.823\n",
            "Loss value did not decrease for 5 epochs\n",
            "Stop training since loss value did not decrease for 5 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-m2wZfyl0Zt1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}